{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscrapping using BeautifulSoup\n",
    "\n",
    "At this module we will learn on how do simple web scrapping using beautiful soup. Web scrapping is one of a method that we can use to colleting the data from internet. At this particular module, we will try to scrap Indonesian inflation rate from www.bi.go.id , it's a official Indonesian bank that provide a couple useful financial information. To do this we will only use a couple default library from python and BeautifulSoup. \n",
    "\n",
    "This module is made as easy and simple as possible which can be used for new developer to learn how to webscrapping using Beautiful Soup. But to do webscrapping you will need a bit of knowlage in `html` which I'll also try to help to explain what you needed at this module, but it is always better if you understand a bit what in `html` first. You can read it quickly at [beautifulsoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc) documentation. It explain what is html and what beautiful soup exactly do at it landing page. \n",
    "\n",
    "## Dependencies\n",
    "\n",
    "Actually to follow this module you only need to install beautifulsoup4 with `pip install beautifulsoup4` and you are good to go. But here some libraries that needed to be installed first that I use at bis module : \n",
    "\n",
    "- beautifulSoup4\n",
    "- pandas\n",
    "- matplotlibs\n",
    "\n",
    "## What is BeautifulSoup\n",
    "\n",
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files. Beautiful Soup 3 only works on Python 2.x, but Beautiful Soup 4 also works on Python 3.x. Beautiful Soup 4 is faster, has more features, and works with third-party parsers\n",
    "like lxml and html5lib.\n",
    "\n",
    "Since beautifulsoup used to pull the data out of a HTML, so first we need to pull out the html first. How we do it? We will use default library `request`. \n",
    "\n",
    "So all this code is doing is sending a GET request to spesific address we give. This is the same type of request your browser sent to view this page, but the only difference is that Requests can't actually render the HTML, so instead you will just get the raw HTML and the other response information.\n",
    "\n",
    "We're using the .get() function here, but Requests allows you to use other functions like .post() and .put() to send those requests as well. At this case we will going to the Bank Indonesia inflation rate page, you can click [here](https://www.bi.go.id/id/moneter/inflasi/data/Default.aspx) to follow what exactly that link goes to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url_get = requests.get('https://www.imdb.com/search/title/?release_date=2019-01-01,2019-12-31.aspx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize what exactly you get from the `request.get`, we can use .content so ee what we exactly get, in here i slice it so it won't make our screen full of the html we get from the page. You can delete the slicing if you want to see what we fully get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\n<!DOCTYPE html>\\n<html\\n    xmlns:og=\"http://ogp.me/ns#\"\\n    xmlns:fb=\"http://www.facebook.com/2008/fbml\">\\n    <head>\\n         \\n        <meta charset=\"utf-8\">\\n        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\\n\\n    <meta name=\"apple-itunes-app\" content=\"app-id=342792525, app-argument=imdb:///?src=mdot\">\\n\\n\\n\\n        <script type=\"text/javascript\">var IMDbTimer={starttime: new Date().getTime(),pt:\\'java\\'};</script>\\n\\n<script>\\n    if (typeof uet == \\'function\\') {\\n      uet(\"bb\", \"LoadTitle\", {wb: 1});\\n    }\\n</script>\\n  <script>(function(t){ (t.events = t.events || {})[\"csm_head_pre_title\"] = new Date().getTime(); })(IMDbTimer);</script>\\n        <title>Released at least 2019-01-01\\n(Sorted by Popularity Ascending) - IMDb</title>\\n  <script>(function(t){ (t.events ='"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_get.content[1:777]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we get a very unstructured and complex html, which actually contains the codes needed to show the webpages on your web browser. But we as human still confused what and where we can use that piece of code, so here where we use the beautifulsoup. Beautiful soup class will result a beautifulsoup object. Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. But youâ€™ll only ever have to deal with about four kinds of objects: `Tag`, `NavigableString`, `BeautifulSoup`, and `Comment`. But at this module we will only use `BeautifulSoup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "soup = BeautifulSoup(url_get.content,\"html.parser\")\n",
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our beautifulsoup looks like. As you can see, the content is the same with our `get_url` object but it's tidier. Also beautifulsoup give us method to make it even more prettier, for tidyness purpouse we slice to only see first 1045 character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html xmlns:fb=\"http://www.facebook.com/2008/fbml\" xmlns:og=\"http://ogp.me/ns#\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <meta content=\"app-id=342792525, app-argument=imdb:///?src=mdot\" name=\"apple-itunes-app\"/>\n",
      "  <script type=\"text/javascript\">\n",
      "   var IMDbTimer={starttime: new Date().getTime(),pt:'java'};\n",
      "  </script>\n",
      "  <script>\n",
      "   if (typeof uet == 'function') {\n",
      "      uet(\"bb\", \"LoadTitle\", {wb: 1});\n",
      "    }\n",
      "  </script>\n",
      "  <script>\n",
      "   (function(t){ (t.events = t.events || {})[\"csm_head_pre_title\"] = new Date().getTime(); })(IMDbTimer);\n",
      "  </script>\n",
      "  <title>\n",
      "   Released at least 2019-01-01\n",
      "(Sorted by Popularity Ascending) - IMDb\n",
      "  </title>\n",
      "  <script>\n",
      "   (function(t){ (t.events = t.events || {})[\"csm_head_post_title\"] = new Date().getTime(); })(IMDbTimer);\n",
      "  </script>\n",
      "  <script>\n",
      "   if (typeof uet == 'function') {\n",
      "      uet(\"be\", \"LoadTitle\", {wb: 1});\n",
      "    }\n",
      "  </script>\n",
      "  <script>\n",
      "   if (typeof uex == 'function') {\n",
      "      uex(\"ld\", \"LoadTitle\", {wb: 1});\n",
      "    }\n",
      "  </scr\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()[:1045])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we already have a tidier html, now we should search the lines that we want to use. Let's back to our web page first.\n",
    "\n",
    "<img src=\"asset/capture.png\">\n",
    "\n",
    "The information that we need are the month and the inflation rate each month, which contain in the table. To know which part of the code refer to that table, we can just move our cusor there, right click, and inspect element. Then we will see something like this. \n",
    "\n",
    "<img src=\"asset/capture_1.png\">\n",
    "\n",
    "From inspect element we know that we need to find the line table with class `table`. We can use the find method at our beautifusoup object. Let's also call our object to see what we get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'prettify'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-12887e0adad1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'table'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'table1'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprettify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'prettify'"
     ]
    }
   ],
   "source": [
    "table = soup.find('table', attrs={'class':'table1'})\n",
    "print(table.prettify()[1:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we find a right lines with information we want. I'll explain a bit about the HTML codes you need to know : \n",
    "\n",
    "- `th` stand for table header/header cell\n",
    "- `tr` stand for table row\n",
    "- `td` stand for standard cell \n",
    "\n",
    "That's all term in HTML `table` that you need to know. Now we can pull it one by one, but we will use looping to make our job easier. But first let's make one object that will find all `tr` in `table` to help us in looping (so we can loop with the length of the table row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-88d1fa1d6975>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# just call 2 founded tr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "tr = table.find_all('tr')\n",
    "tr[:2] # just call 2 founded tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here what the looping do to scrap the information: \n",
    "\n",
    "- First we need to establish a placeholder to receive the information that we scrap. \n",
    "- We named it `temp` and it's a tuple. \n",
    "- Then we will make a loop from one until the the length of the table row, \n",
    "- which we will find all cell of the column one and two which contain period and the inflation rate. \n",
    "- Then we will append it to our tuple that we prepared before, \n",
    "- every one iteration we will scrap one line of the table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('April 2020', '2.67 %'),\n",
       " ('Maret 2020', '2.96 %'),\n",
       " ('Februari 2020', '2.98 %'),\n",
       " ('Januari 2020', '2.68 %'),\n",
       " ('Desember 2019', '2.72 %'),\n",
       " ('Nopember 2019', '3.00 %'),\n",
       " ('Oktober 2019', '3.13 %'),\n",
       " ('September 2019', '3.39 %'),\n",
       " ('Agustus 2019', '3.49 %'),\n",
       " ('Juli 2019', '3.32 %'),\n",
       " ('Juni 2019', '3.28 %'),\n",
       " ('Mei 2019', '3.32 %'),\n",
       " ('April 2019', '2.83 %'),\n",
       " ('Maret 2019', '2.48 %'),\n",
       " ('Februari 2019', '2.57 %'),\n",
       " ('Januari 2019', '2.82 %'),\n",
       " ('Desember 2018', '3.13 %'),\n",
       " ('Nopember 2018', '3.23 %'),\n",
       " ('Oktober 2018', '3.16 %'),\n",
       " ('September 2018', '2.88 %')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [] #initiating a tuple\n",
    "\n",
    "for i in range(1, len(tr)):\n",
    "    row = table.find_all('tr')[i]\n",
    "    \n",
    "    #get bulan\n",
    "    period = row.find_all('td')[0].text\n",
    "    period = period.strip() #for removing the excess whitespace\n",
    "    \n",
    "    #get inflasi\n",
    "    inflation = row.find_all('td')[1].text\n",
    "    inflation = inflation.strip() #for removing the excess whitespace\n",
    "    \n",
    "    temp.append((period,inflation)) \n",
    "    \n",
    "temp "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That the result we get, At this point we can input it to a pandas' DataFrame and do usual data analysis, but if you notice the original webpage give us reversed information. To do a further analysis let's reverse our tuple we can use `::-1` to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('September 2018', '2.88 %'),\n",
       " ('Oktober 2018', '3.16 %'),\n",
       " ('Nopember 2018', '3.23 %'),\n",
       " ('Desember 2018', '3.13 %'),\n",
       " ('Januari 2019', '2.82 %'),\n",
       " ('Februari 2019', '2.57 %'),\n",
       " ('Maret 2019', '2.48 %'),\n",
       " ('April 2019', '2.83 %'),\n",
       " ('Mei 2019', '3.32 %'),\n",
       " ('Juni 2019', '3.28 %'),\n",
       " ('Juli 2019', '3.32 %'),\n",
       " ('Agustus 2019', '3.49 %'),\n",
       " ('September 2019', '3.39 %'),\n",
       " ('Oktober 2019', '3.13 %'),\n",
       " ('Nopember 2019', '3.00 %'),\n",
       " ('Desember 2019', '2.72 %'),\n",
       " ('Januari 2020', '2.68 %'),\n",
       " ('Februari 2020', '2.98 %'),\n",
       " ('Maret 2020', '2.96 %'),\n",
       " ('April 2020', '2.67 %')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = temp[::-1]\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then after we fix our tuple a bit, as usual we will input it to pandas' dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>inflation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>September 2018</td>\n",
       "      <td>2.88 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oktober 2018</td>\n",
       "      <td>3.16 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nopember 2018</td>\n",
       "      <td>3.23 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Desember 2018</td>\n",
       "      <td>3.13 %</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Januari 2019</td>\n",
       "      <td>2.82 %</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           period inflation\n",
       "0  September 2018    2.88 %\n",
       "1    Oktober 2018    3.16 %\n",
       "2   Nopember 2018    3.23 %\n",
       "3   Desember 2018    3.13 %\n",
       "4    Januari 2019    2.82 %"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(temp, columns = ('period','inflation'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this just usual stuff, we can clean the data or save it to csv let's do a bit cleaning so we can do a bit of visualisation. We will change the inflation to float datatype, but before we can do that we need to clean the \" %\" first. After the it on the right data type we can do simple visualisation using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15ca2c12f08>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['inflation'] = df['inflation'].str.replace(\" %\",\"\")\n",
    "df['inflation'] = df['inflation'].astype('float64')\n",
    "\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclution when you don't have a direct access to a data from a website you can always do the scrapping method. There is a couple library that can do same task like `scrapy` that can build bot to automaticly crawl data, but we choose beautiful soup since it's more beginner friendly and a helpful utility that allows a programmer to get specific elements out of a webpage (for example, a list of images). \n",
    "\n",
    "After this you also can implement the scrapping to one function and put it at the flask webapp, which you can find the demo [here](https://github.com/t3981-h/LikesRatio) and you can go to inflation branch to see example that scrap a same page or you can visit [Pricemate](https://github.com/onlyphantom/pricemate). Which scrap tiket.com data to get train price list. I hope this short module help you to understand and can kickstart you to learn more about webscrapping using Beautifulsoup. Also feel free to contact us at mentor@algorit.ma if you have more question.\n",
    "\n",
    "Happy learning~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
